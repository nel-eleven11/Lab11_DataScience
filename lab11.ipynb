{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ff87eeb1",
      "metadata": {
        "id": "ff87eeb1"
      },
      "source": [
        "# Laboratorio 11 - Data Science\n",
        "## Proyecto de Consultoría Regresión Logística\n",
        "- Nelson García Bravatti\n",
        "- Christian Echeverría\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7922a986",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "7922a986"
      },
      "outputs": [],
      "source": [
        "!pip -q install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8b8b2da4",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "8b8b2da4",
        "outputId": "5cca97f0-ee3b-4fff-a2fd-48ffb15d3c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.1\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql import types as T\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.linalg import DenseMatrix\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Lab DF — Abandono\").getOrCreate()\n",
        "print(\"Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4891bda5",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "4891bda5",
        "outputId": "1d799dc4-e400-4e46-a339-0f49cbc889c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
            "|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
            "|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
            "|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
            "|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
            "+----------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = 'abandono_clientes.csv'\n",
        "\n",
        "df = (\n",
        "    spark.read\n",
        "         .option(\"header\", True)\n",
        "         .option(\"inferSchema\", True)\n",
        "         .csv(file_path)\n",
        ")\n",
        "\n",
        "# Ver las primeras filas del dataframe\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9869f606",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9869f606",
        "outputId": "49a1263a-c13a-462f-a6e5-a413da3ccc2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            " |-- Churn: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = 'clientes_nuevos.csv'\n",
        "\n",
        "test_df = (\n",
        "    spark.read\n",
        "         .option(\"header\", True)\n",
        "         .option(\"inferSchema\", True)\n",
        "         .csv(file_path2)\n",
        ")\n",
        "\n",
        "# Ver las primeras filas del dataframe\n",
        "test_df.show(5)"
      ],
      "metadata": {
        "id": "nj2aw1ZC_e3v",
        "outputId": "7c8764b1-5dbe-4983-dd8f-364c387e8481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nj2aw1ZC_e3v",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
            "|         Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|         Company|\n",
            "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
            "| Andrew Mccall|37.0|       9935.53|              1| 7.71|      8.0|2011-08-29 18:37:54|38612 Johnny Stra...|        King Ltd|\n",
            "|Michele Wright|23.0|       7526.94|              1| 9.28|     15.0|2013-07-22 18:19:54|21083 Nicole Junc...|   Cannon-Benson|\n",
            "|  Jeremy Chang|65.0|         100.0|              1|  1.0|     15.0|2006-12-11 07:48:13|085 Austin Views ...|Barron-Robertson|\n",
            "|Megan Ferguson|32.0|        6487.5|              0|  9.4|     14.0|2016-10-28 05:32:13|922 Wright Branch...|   Sexton-Golden|\n",
            "|  Taylor Young|32.0|      13147.71|              1| 10.0|      8.0|2012-03-20 00:36:46|Unit 0789 Box 073...|        Wood LLC|\n",
            "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.printSchema()"
      ],
      "metadata": {
        "id": "BRg8dwgD_evS",
        "outputId": "b4fef5b3-8a69-4a19-afd4-9cf150ec6a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BRg8dwgD_evS",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Names: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- Total_Purchase: double (nullable = true)\n",
            " |-- Account_Manager: integer (nullable = true)\n",
            " |-- Years: double (nullable = true)\n",
            " |-- Num_Sites: double (nullable = true)\n",
            " |-- Onboard_date: timestamp (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            " |-- Company: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análisis del Dataset:"
      ],
      "metadata": {
        "id": "Jl_y7lCr-YZY"
      },
      "id": "Jl_y7lCr-YZY"
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 1) Dimensión, duplicados ----------\n",
        "n_rows = df.count()\n",
        "n_cols = len(df.columns)\n",
        "print(f\"Filas: {n_rows}  |  Columnas: {n_cols}\")\n",
        "\n",
        "dup_company = (df.groupBy(\"Company\").count()\n",
        "                 .filter(F.col(\"count\") > 1)\n",
        "                 .count())\n",
        "print(f\"Empresas duplicadas por 'Company': {dup_company}\")"
      ],
      "metadata": {
        "id": "EoBTh7jjCRI-",
        "outputId": "2858593b-9bcf-486c-dd29-80e437543baa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EoBTh7jjCRI-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas: 900  |  Columnas: 10\n",
            "Empresas duplicadas por 'Company': 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 2) Nulos y tipos ----------\n",
        "nulls = []\n",
        "for c in df.columns:\n",
        "    nulls.append((c, df.filter(F.col(c).isNull()).count()))\n",
        "spark.createDataFrame(nulls, [\"columna\", \"nulos\"]).show(n=100, truncate=False)\n",
        "\n",
        "# Rangos rápidos (numéricas)\n",
        "num_cols = [\"Age\",\"Total_Purchase\",\"Years\",\"Num_Sites\"]\n",
        "(\n",
        "  df.select([F.min(c).alias(f\"min_{c}\") for c in num_cols] +\n",
        "            [F.max(c).alias(f\"max_{c}\") for c in num_cols] +\n",
        "            [F.avg(c).alias(f\"avg_{c}\") for c in num_cols])\n",
        ").show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "thk1svAICVEC",
        "outputId": "8173f3d5-14fd-482a-f8ae-44657a324b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "thk1svAICVEC",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|columna        |nulos|\n",
            "+---------------+-----+\n",
            "|Names          |0    |\n",
            "|Age            |0    |\n",
            "|Total_Purchase |0    |\n",
            "|Account_Manager|0    |\n",
            "|Years          |0    |\n",
            "|Num_Sites      |0    |\n",
            "|Onboard_date   |0    |\n",
            "|Location       |0    |\n",
            "|Company        |0    |\n",
            "|Churn          |0    |\n",
            "+---------------+-----+\n",
            "\n",
            "+-------+------------------+---------+-------------+-------+------------------+---------+-------------+-----------------+------------------+----------------+-----------------+\n",
            "|min_Age|min_Total_Purchase|min_Years|min_Num_Sites|max_Age|max_Total_Purchase|max_Years|max_Num_Sites|avg_Age          |avg_Total_Purchase|avg_Years       |avg_Num_Sites    |\n",
            "+-------+------------------+---------+-------------+-------+------------------+---------+-------------+-----------------+------------------+----------------+-----------------+\n",
            "|22.0   |100.0             |1.0      |3.0          |65.0   |18026.01          |9.15     |14.0         |41.81666666666667|10062.82403333334 |5.27315555555555|8.587777777777777|\n",
            "+-------+------------------+---------+-------------+-------+------------------+---------+-------------+-----------------+------------------+----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 3) Balance de clases ----------\n",
        "class_balance = (df.groupBy(\"Churn\").count()\n",
        "                   .withColumn(\"prop\", F.col(\"count\")/n_rows))\n",
        "class_balance.show()\n"
      ],
      "metadata": {
        "id": "oeh_Gol6CWfy",
        "outputId": "01a18099-9ece-4ed5-bd58-dafb5b752588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "oeh_Gol6CWfy",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+-------------------+\n",
            "|Churn|count|               prop|\n",
            "+-----+-----+-------------------+\n",
            "|    1|  150|0.16666666666666666|\n",
            "|    0|  750| 0.8333333333333334|\n",
            "+-----+-----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 4) Stats por clase ----------\n",
        "stats_by_churn = (\n",
        "    df.groupBy(\"Churn\")\n",
        "      .agg(\n",
        "          F.count(\"*\").alias(\"n\"),\n",
        "          *[F.mean(c).alias(f\"mean_{c}\") for c in num_cols],\n",
        "          *[F.expr(f\"percentile_approx({c}, 0.5)\").alias(f\"p50_{c}\") for c in num_cols],\n",
        "          *[F.expr(f\"percentile_approx({c}, array(0.25,0.75))\").alias(f\"IQR_{c}\") for c in num_cols]\n",
        "      )\n",
        ")\n",
        "stats_by_churn.show(truncate=False)"
      ],
      "metadata": {
        "id": "7r4ER0NECX62",
        "outputId": "025aa560-8088-4d0b-872e-e3d5ee11bf82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7r4ER0NECX62",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+-----------------+-------------------+------------------+-----------------+-------+------------------+---------+-------------+------------+-------------------+------------+-------------+\n",
            "|Churn|n  |mean_Age         |mean_Total_Purchase|mean_Years        |mean_Num_Sites   |p50_Age|p50_Total_Purchase|p50_Years|p50_Num_Sites|IQR_Age     |IQR_Total_Purchase |IQR_Years   |IQR_Num_Sites|\n",
            "+-----+---+-----------------+-------------------+------------------+-----------------+-------+------------------+---------+-------------+------------+-------------------+------------+-------------+\n",
            "|1    |150|42.99333333333333|10192.179933333337 |5.8835999999999995|10.66            |43.0   |10271.19          |5.79     |11.0         |[38.0, 47.0]|[8563.24, 11758.69]|[5.12, 6.68]|[10.0, 12.0] |\n",
            "|0    |750|41.58133333333333|10036.952853333332 |5.1510666666666625|8.173333333333334|41.0   |9993.5            |5.08     |8.0          |[37.0, 46.0]|[8475.8, 11764.35] |[4.36, 5.99]|[7.0, 9.0]   |\n",
            "+-----+---+-----------------+-------------------+------------------+-----------------+-------+------------------+---------+-------------+------------+-------------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 5) Ingeniería de fecha: Tenure desde Onboard_date ----------\n",
        "max_date = df.agg(F.max(\"Onboard_date\").alias(\"maxd\")).collect()[0][\"maxd\"]\n",
        "df2 = df.withColumn(\"Tenure_years_from_onboard\",\n",
        "                    (F.datediff(F.lit(max_date), F.col(\"Onboard_date\"))/365.25).cast(\"double\"))\n",
        "\n",
        "(\n",
        "  df2.select(\n",
        "      F.avg(F.abs(F.col(\"Tenure_years_from_onboard\") - F.col(\"Years\"))).alias(\"MAE_Years_vs_Tenure\"),\n",
        "      F.corr(\"Tenure_years_from_onboard\",\"Years\").alias(\"corr_Years_vs_Tenure\")\n",
        "  ).show()\n",
        ")\n"
      ],
      "metadata": {
        "id": "llXpVI29CX19",
        "outputId": "14338e32-f244-4881-933f-f86126c0d155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "llXpVI29CX19",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+\n",
            "|MAE_Years_vs_Tenure|corr_Years_vs_Tenure|\n",
            "+-------------------+--------------------+\n",
            "| 2.9261441630542295| 0.04491650416398004|\n",
            "+-------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 6) Leakage check: Account_Manager  ----------\n",
        "# Tabla de contingencia y proporciones\n",
        "ct = (df.groupBy(\"Account_Manager\",\"Churn\").count()\n",
        "        .withColumn(\"prop\", F.col(\"count\")/F.sum(\"count\").over(Window.partitionBy(\"Account_Manager\"))))\n",
        "ct.orderBy(\"Account_Manager\",\"Churn\").show()\n",
        "\n",
        "# Chi-cuadrado\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.stat import ChiSquareTest\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Preparar vector de features categóricas y label\n",
        "assembler = VectorAssembler(inputCols=[\"Account_Manager\"], outputCol=\"features\")\n",
        "chi_df = assembler.setHandleInvalid(\"keep\").transform(df.select(\"Account_Manager\",\"Churn\").dropna())\n",
        "chi = ChiSquareTest.test(chi_df, \"features\", \"Churn\").head()\n",
        "print(f\"Chi2 p-value Account_Manager ~ Churn: {chi.pValues[0]}\")\n"
      ],
      "metadata": {
        "id": "fiNZp1JkCXzN",
        "outputId": "4b79ee8b-255b-440c-f83e-a03786c59d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fiNZp1JkCXzN",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+-----+-------------------+\n",
            "|Account_Manager|Churn|count|               prop|\n",
            "+---------------+-----+-----+-------------------+\n",
            "|              0|    0|  401| 0.8586723768736617|\n",
            "|              0|    1|   66|0.14132762312633834|\n",
            "|              1|    0|  349| 0.8060046189376443|\n",
            "|              1|    1|   84|0.19399538106235567|\n",
            "+---------------+-----+-----+-------------------+\n",
            "\n",
            "Chi2 p-value Account_Manager ~ Churn: 0.03414770918874699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 7) Correlaciones numéricas ----------\n",
        "vec_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"features_num\")\n",
        "num_vec = vec_assembler.setHandleInvalid(\"skip\").transform(df.select(num_cols).dropna())\n",
        "corr_mat = Correlation.corr(num_vec, \"features_num\", \"pearson\").head()[0]  # DenseMatrix\n",
        "# Imprimir matriz con nombres\n",
        "def pretty_corr(names, m: DenseMatrix):\n",
        "    arr = m.toArray().tolist()\n",
        "    header = \"        \" + \"  \".join([f\"{c:>14}\" for c in names])\n",
        "    print(header)\n",
        "    for i, row in enumerate(arr):\n",
        "        print(f\"{names[i]:>8}  \" + \"  \".join([f\"{v:14.3f}\" for v in row]))\n",
        "pretty_corr(num_cols, corr_mat)\n"
      ],
      "metadata": {
        "id": "gGlmV3FwCXv1",
        "outputId": "8df04527-a38a-467e-d51c-2c5ce59bb59d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gGlmV3FwCXv1",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Age  Total_Purchase           Years       Num_Sites\n",
            "     Age           1.000          -0.037           0.006          -0.006\n",
            "Total_Purchase          -0.037           1.000          -0.006          -0.003\n",
            "   Years           0.006          -0.006           1.000           0.052\n",
            "Num_Sites          -0.006          -0.003           0.052           1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- 8) Cardinalidad de categorías ----------\n",
        "(\n",
        "  df.agg(\n",
        "    F.countDistinct(\"Names\").alias(\"uniq_Names\"),\n",
        "    F.countDistinct(\"Location\").alias(\"uniq_Location\"),\n",
        "    F.countDistinct(\"Company\").alias(\"uniq_Company\")\n",
        "  ).show()\n",
        ")\n",
        "\n",
        "# Top ubicaciones (si aporta algo regional)\n",
        "(df.groupBy(\"Location\")\n",
        "   .agg(F.count(\"*\").alias(\"n\"), F.mean(\"Churn\").alias(\"churn_rate\"))\n",
        "   .orderBy(F.desc(\"n\"))\n",
        "   .show(20, truncate=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "mj-QVWaiCXjG",
        "outputId": "e5650ed8-14b9-4cec-9fc9-473e72e10f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mj-QVWaiCXjG",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+------------+\n",
            "|uniq_Names|uniq_Location|uniq_Company|\n",
            "+----------+-------------+------------+\n",
            "|       899|          900|         873|\n",
            "+----------+-------------+------------+\n",
            "\n",
            "+---------------------------------------------------------------+---+----------+\n",
            "|Location                                                       |n  |churn_rate|\n",
            "+---------------------------------------------------------------+---+----------+\n",
            "|062 Trevor Falls Suite 665 North Mathewchester, MH 93744       |1  |1.0       |\n",
            "|066 Jenkins Walks Barbaramouth, LA 76409                       |1  |0.0       |\n",
            "|45946 Day Springs Mendozastad, NJ 46404                        |1  |1.0       |\n",
            "|143 Andrea Flat Lake Michael, ID 33149                         |1  |0.0       |\n",
            "|Unit 2093 Box 1530 DPO AA 53596-7800                           |1  |0.0       |\n",
            "|399 Herbert Key Port Thomas, PR 14265                          |1  |0.0       |\n",
            "|104 Ruben Rapid Apt. 107 New Andrea, FM 58602                  |1  |0.0       |\n",
            "|930 Carrie Harbor Suite 044 New Adamtown, MP 74903             |1  |0.0       |\n",
            "|8202 Jade Unions Suite 557 South Wesley, MS 12025              |1  |0.0       |\n",
            "|USCGC Bailey FPO AA 06202-5064                                 |1  |0.0       |\n",
            "|893 Carla Trace Suite 132 Lake Aliciaport, AR 87567            |1  |0.0       |\n",
            "|446 Rodney Ridge Suite 282 West Williamside, MA 83236          |1  |0.0       |\n",
            "|30668 Isabella Freeway Suite 428 Lake Kellyhaven, MP 89074-5017|1  |1.0       |\n",
            "|911 Kent Point Anthonytown, KS 47499                           |1  |0.0       |\n",
            "|078 Nunez Haven Suite 032 East Bradley, SC 36621-1197          |1  |0.0       |\n",
            "|PSC 5667, Box 8312 APO AP 00654                                |1  |0.0       |\n",
            "|4972 Michael Village Suite 788 West Rachelstad, NH 04946-6243  |1  |0.0       |\n",
            "|567 Ian Loop Lambertberg, MA 68810-6480                        |1  |0.0       |\n",
            "|482 Wells Mountain New Jason, AL 66002                         |1  |0.0       |\n",
            "|7259 Brown Street Apt. 385 Monicaport, GU 05916-8374           |1  |1.0       |\n",
            "+---------------------------------------------------------------+---+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Division del dataset y preparación:\n"
      ],
      "metadata": {
        "id": "PMoD3sZ6ArxJ"
      },
      "id": "PMoD3sZ6ArxJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# ancla temporal = fecha máxima observada (consistente con tu EDA)\n",
        "anchor_date = df.agg(F.max(\"Onboard_date\").alias(\"maxd\")).collect()[0][\"maxd\"]\n",
        "\n",
        "# Ingeniería de variables\n",
        "df_feat = (\n",
        "    df\n",
        "    .withColumn(\n",
        "        \"Tenure_from_onboard\",\n",
        "        (F.datediff(F.lit(anchor_date), F.col(\"Onboard_date\"))/F.lit(365.25)).cast(\"double\")\n",
        "    )\n",
        "    .withColumn(\"Sites_per_Year\", (F.col(\"Num_Sites\")/(F.col(\"Years\")+F.lit(1e-6))).cast(\"double\"))\n",
        "    .withColumn(\"Purchase_per_Site\", (F.col(\"Total_Purchase\")/(F.col(\"Num_Sites\")+F.lit(1e-6))).cast(\"double\"))\n",
        ")\n",
        "\n",
        "# Columnas finales por variante\n",
        "features_base = [\n",
        "    \"Age\", \"Total_Purchase\", \"Years\", \"Num_Sites\",\n",
        "    \"Tenure_from_onboard\", \"Sites_per_Year\", \"Purchase_per_Site\"\n",
        "]\n",
        "features_with_am = features_base + [\"Account_Manager\"]\n"
      ],
      "metadata": {
        "id": "W6tnHC7J-uTp"
      },
      "id": "W6tnHC7J-uTp",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Añadir columna aleatoria por clase para split estratificado\n",
        "pos = df_feat.filter(F.col(\"Churn\") == 1).withColumn(\"rand\", F.rand(seed=42))\n",
        "neg = df_feat.filter(F.col(\"Churn\") == 0).withColumn(\"rand\", F.rand(seed=42))\n",
        "\n",
        "train = pos.filter(\"rand <= 0.7\").unionByName(neg.filter(\"rand <= 0.7\")).drop(\"rand\")\n",
        "test  = pos.filter(\"rand > 0.7\").unionByName(neg.filter(\"rand > 0.7\")).drop(\"rand\")\n",
        "\n",
        "print(\"Train count:\", train.count(), \"| Test count:\", test.count())\n",
        "train.groupBy(\"Churn\").count().show()\n",
        "test.groupBy(\"Churn\").count().show()\n"
      ],
      "metadata": {
        "id": "UFCYDUkq-uRy",
        "outputId": "18cacdfd-b20e-4447-d3f7-2cb58d665671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UFCYDUkq-uRy",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train count: 659 | Test count: 241\n",
            "+-----+-----+\n",
            "|Churn|count|\n",
            "+-----+-----+\n",
            "|    1|  104|\n",
            "|    0|  555|\n",
            "+-----+-----+\n",
            "\n",
            "+-----+-----+\n",
            "|Churn|count|\n",
            "+-----+-----+\n",
            "|    1|   46|\n",
            "|    0|  195|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesos de clase: mayor peso a la clase positiva (churn=1)\n",
        "n_train = train.count()\n",
        "n_pos = train.filter(F.col(\"Churn\") == 1).count()\n",
        "n_neg = n_train - n_pos\n",
        "pos_weight = n_neg / float(n_pos)  # ~ proporción negativas/positivas\n",
        "\n",
        "train_w = train.withColumn(\n",
        "    \"classWeightCol\",\n",
        "    F.when(F.col(\"Churn\") == 1, F.lit(pos_weight)).otherwise(F.lit(1.0))\n",
        ")\n",
        "\n",
        "# Assembler por variante\n",
        "assembler_A = VectorAssembler(inputCols=features_base, outputCol=\"features\", handleInvalid=\"skip\")\n",
        "assembler_B = VectorAssembler(inputCols=features_with_am, outputCol=\"features\", handleInvalid=\"skip\")\n"
      ],
      "metadata": {
        "id": "Vit-wWyA-uO7"
      },
      "id": "Vit-wWyA-uO7",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Predictivo"
      ],
      "metadata": {
        "id": "xPx36pVMC68U"
      },
      "id": "xPx36pVMC68U"
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"Churn\",\n",
        "    weightCol=\"classWeightCol\",  # usa pesos\n",
        "    predictionCol=\"prediction\",\n",
        "    probabilityCol=\"probability\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    maxIter=200\n",
        ")\n",
        "\n",
        "paramGrid = (\n",
        "    ParamGridBuilder()\n",
        "    .addGrid(lr.regParam, [0.0, 0.01, 0.1, 0.5])\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # Ridge/Lasso/Mix\n",
        "    .build()\n",
        ")\n",
        "\n",
        "evaluator_pr = BinaryClassificationEvaluator(\n",
        "    labelCol=\"Churn\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderPR\"\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler_A, lr])\n",
        "\n",
        "tvs = TrainValidationSplit(\n",
        "    estimator=pipeline,\n",
        "    estimatorParamMaps=paramGrid,\n",
        "    evaluator=evaluator_pr,\n",
        "    trainRatio=0.8,\n",
        "    parallelism=2\n",
        ")\n",
        "\n",
        "evaluator_roc = BinaryClassificationEvaluator(\n",
        "    labelCol=\"Churn\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    metricName=\"areaUnderROC\"\n",
        ")\n",
        "\n",
        "model = tvs.fit(train_w)\n",
        "preds = model.transform(test)\n",
        "\n",
        "auc_pr  = evaluator_pr.evaluate(preds)\n",
        "auc_roc = evaluator_roc.evaluate(preds)\n",
        "print(f\"[LR - CON Account_Manager] PR-AUC: {auc_pr:.4f} | ROC-AUC: {auc_roc:.4f}\")\n"
      ],
      "metadata": {
        "id": "rOWC1k9s-uKx",
        "outputId": "0ba8e0b2-29f6-4ebb-bc15-573e14c8d493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rOWC1k9s-uKx",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR - CON Account_Manager] PR-AUC: 0.7991 | ROC-AUC: 0.9172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml.functions import vector_to_array  # Disponible en Spark 3.0+\n",
        "\n",
        "# Crea una columna con p(churn=1)\n",
        "preds_fix = preds.withColumn(\"prob1\", vector_to_array(\"probability\").getItem(1))\n",
        "\n",
        "def metrics_at_threshold(pred_df, thr, prob_col=\"prob1\", label_col=\"Churn\"):\n",
        "    scored = pred_df.withColumn(\"yhat\", (F.col(prob_col) >= F.lit(thr)).cast(\"int\"))\n",
        "    agg = (scored\n",
        "           .groupBy()\n",
        "           .agg(\n",
        "               F.sum(F.when((F.col(label_col)==1) & (F.col(\"yhat\")==1), 1).otherwise(0)).alias(\"TP\"),\n",
        "               F.sum(F.when((F.col(label_col)==0) & (F.col(\"yhat\")==1), 1).otherwise(0)).alias(\"FP\"),\n",
        "               F.sum(F.when((F.col(label_col)==0) & (F.col(\"yhat\")==0), 1).otherwise(0)).alias(\"TN\"),\n",
        "               F.sum(F.when((F.col(label_col)==1) & (F.col(\"yhat\")==0), 1).otherwise(0)).alias(\"FN\"),\n",
        "           )).collect()[0]\n",
        "    TP, FP, TN, FN = agg[\"TP\"], agg[\"FP\"], agg[\"TN\"], agg[\"FN\"]\n",
        "    precision = TP / float(TP+FP) if (TP+FP)>0 else 0.0\n",
        "    recall    = TP / float(TP+FN) if (TP+FN)>0 else 0.0\n",
        "    f1        = (2*precision*recall)/float(precision+recall) if (precision+recall)>0 else 0.0\n",
        "    return TP, FP, TN, FN, precision, recall, f1\n",
        "\n",
        "thresholds = [x/100.0 for x in range(10, 91, 5)]\n",
        "rows = [ (t, *metrics_at_threshold(preds_fix, t)) for t in thresholds ]\n",
        "\n",
        "schema = [\"threshold\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"]\n",
        "spark.createDataFrame(rows, schema).orderBy(F.desc(\"F1\")).show(truncate=False)\n",
        "\n",
        "best_row = sorted(rows, key=lambda x: x[-1], reverse=True)[0]\n",
        "best_thr = best_row[0]\n",
        "print(f\"Mejor umbral por F1: {best_thr:.2f}\")\n"
      ],
      "metadata": {
        "id": "w7fKFoYf-uEe",
        "outputId": "da3774ed-585f-44bf-8659-d62918adbc11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "w7fKFoYf-uEe",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+---+---+---+-------------------+--------------------+--------------------+\n",
            "|threshold|TP |FP |TN |FN |precision          |recall              |F1                  |\n",
            "+---------+---+---+---+---+-------------------+--------------------+--------------------+\n",
            "|0.55     |39 |24 |171|7  |0.6190476190476191 |0.8478260869565217  |0.7155963302752294  |\n",
            "|0.65     |30 |8  |187|16 |0.7894736842105263 |0.6521739130434783  |0.7142857142857143  |\n",
            "|0.6      |33 |18 |177|13 |0.6470588235294118 |0.717391304347826   |0.6804123711340206  |\n",
            "|0.5      |40 |36 |159|6  |0.5263157894736842 |0.8695652173913043  |0.6557377049180327  |\n",
            "|0.45     |41 |48 |147|5  |0.4606741573033708 |0.8913043478260869  |0.6074074074074074  |\n",
            "|0.7      |20 |3  |192|26 |0.8695652173913043 |0.43478260869565216 |0.5797101449275363  |\n",
            "|0.4      |43 |68 |127|3  |0.38738738738738737|0.9347826086956522  |0.5477707006369428  |\n",
            "|0.75     |16 |1  |194|30 |0.9411764705882353 |0.34782608695652173 |0.5079365079365079  |\n",
            "|0.35     |43 |88 |107|3  |0.3282442748091603 |0.9347826086956522  |0.48587570621468934 |\n",
            "|0.3      |45 |108|87 |1  |0.29411764705882354|0.9782608695652174  |0.45226130653266333 |\n",
            "|0.25     |45 |140|55 |1  |0.24324324324324326|0.9782608695652174  |0.38961038961038963 |\n",
            "|0.2      |46 |158|37 |0  |0.22549019607843138|1.0                 |0.368               |\n",
            "|0.8      |10 |0  |195|36 |1.0                |0.21739130434782608 |0.3571428571428571  |\n",
            "|0.15     |46 |174|21 |0  |0.20909090909090908|1.0                 |0.3458646616541353  |\n",
            "|0.1      |46 |191|4  |0  |0.1940928270042194 |1.0                 |0.3250883392226148  |\n",
            "|0.85     |4  |0  |195|42 |1.0                |0.08695652173913043 |0.16                |\n",
            "|0.9      |1  |0  |195|45 |1.0                |0.021739130434782608|0.042553191489361694|\n",
            "+---------+---+---+---+---+-------------------+--------------------+--------------------+\n",
            "\n",
            "Mejor umbral por F1: 0.55\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}